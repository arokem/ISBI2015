{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import dipy.reconst.sfm as sfm\n",
    "import dipy.reconst.csdeconv as csd\n",
    "import dipy.reconst.dti as dti\n",
    "import dipy.core.gradients as grad\n",
    "import dipy.reconst.cross_validation as xval\n",
    "import dipy.data as dpd\n",
    "import utils\n",
    "import model as mm \n",
    "from model import Model, BiExponentialIsotropicModel, my_responses\n",
    "from parallelization import parallelization\n",
    "import csv\n",
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sphere = dpd.get_sphere()\n",
    "#sphere = sphere.subdivide(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_dict = utils.read_data()\n",
    "data = data_dict['seen']['signal'][:, range(1)]\n",
    "bvals = data_dict['seen']['bvals']\n",
    "bvecs = data_dict['seen']['bvecs']\n",
    "delta = data_dict['seen']['delta']\n",
    "Delta = data_dict['seen']['Delta']\n",
    "te = data_dict['seen']['TE']\n",
    "g = data_dict['seen']['g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_seen = []\n",
    "data_unseen = []\n",
    "te_seen = []\n",
    "te_unseen = []\n",
    "gtab_seen = []\n",
    "gtab_unseen = []\n",
    "g_seen = []\n",
    "g_unseen = []\n",
    "\n",
    "mask = utils.create_shells()\n",
    "for m in range(data.shape[-1]): # for every voxel\n",
    "    for j in range(0, len(mask)): # for every TE\n",
    "        for i in range(0, len(mask[j])): # for every shell\n",
    "            mask_unseen = mask[j][i]\n",
    "            mask_seen = np.invert(mask_unseen)\n",
    "            data_seen.append(data[mask_seen, m])\n",
    "            data_unseen.append(data[mask_unseen, m])\n",
    "            te_seen.append(te[mask_seen])\n",
    "            te_unseen.append(te[mask_unseen])\n",
    "            g_unseen.append(g[mask_unseen])\n",
    "            g_seen.append(g[mask_seen])\n",
    "            bvals_seen_temp = bvals[mask_seen]\n",
    "            bvecs_seen_temp = bvecs[mask_seen]\n",
    "            delta_seen_temp = delta[mask_seen]\n",
    "            Delta_seen_temp = Delta[mask_seen]\n",
    "            gtab_seen.append(grad.gradient_table(bvals_seen_temp, bvecs_seen_temp, big_delta=Delta_seen_temp, small_delta=delta_seen_temp))\n",
    "            bvals_unseen_temp = bvals[mask_unseen]\n",
    "            bvecs_unseen_temp = bvecs[mask_unseen]\n",
    "            delta_unseen_temp = delta[mask_unseen]\n",
    "            Delta_unseen_temp = Delta[mask_unseen]\n",
    "            gtab_unseen.append(grad.gradient_table(bvals_unseen_temp, bvecs_unseen_temp, big_delta=Delta_unseen_temp, small_delta=delta_unseen_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 shells, 11 TEs, 6 Voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Version 1\n",
    "alphas = [1e-5]\n",
    "l1_ratios = [0.1]\n",
    "\n",
    "# Version 2\n",
    "alphas = [1e-9, 1e-3]\n",
    "l1_ratios = [0.3, 0.9]\n",
    "\n",
    "# Version 3\n",
    "alphas = [1e-12, 1e-5]\n",
    "l1_ratios = [0.05, 0.3]\n",
    "\n",
    "# Version 4\n",
    "alphas = [5e-5, 1e-5, 5e-6]\n",
    "l1_ratios = [0.25, 0.3, 0.35]\n",
    "\n",
    "# Version 5\n",
    "alphas = [5e-6, 5e-7, 5e-8, 5e-9]\n",
    "l1_ratios = [0.35, 0.4, 0.45]\n",
    "'''\n",
    "# Version 6\n",
    "alphas = [1e-6, 5e-7, 1e-7]\n",
    "l1_ratios = [0.375, 0.4, 0.425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_variations = len(alphas) * len(l1_ratios)\n",
    "n_voxels = len(data_seen)\n",
    "n = n_voxels * n_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_grid, l1_ratio_grid = np.meshgrid(alphas, l1_ratios)\n",
    "alpha_grid = np.reshape(alpha_grid, (n_variations, -1)).squeeze()\n",
    "l1_ratio_grid = np.reshape(l1_ratio_grid, (n_variations, -1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = np.repeat(alpha_grid, n_voxels).tolist()\n",
    "l1_ratio = np.repeat(l1_ratio_grid, n_voxels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solvers = []\n",
    "for a, l in zip(alpha, l1_ratio):\n",
    "    solvers.append(lm.ElasticNet(l1_ratio=l, alpha=a, positive=True, warm_start=True, max_iter=25000, fit_intercept=True, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = parallelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelization starts on 64 CPUs.\n",
      "  3%      0.01min remaining\n",
      " 12%      0.01min remaining\n",
      " 15%      0.01min remaining\n",
      "  6%      0.01min remaining\n",
      "  9%      0.01min remaining\n",
      " 21%      0.01min remaining\n",
      " 24%      0.01min remaining\n",
      " 30%      0.01min remaining\n",
      " 27%      0.01min remaining\n",
      " 33%      0.01min remaining\n",
      " 39%      0.01min remaining\n",
      " 36%      0.01min remaining\n",
      " 42%      0.01min remaining\n",
      " 45%      0.01min remaining\n",
      " 18%      0.01min remaining\n",
      " 48%      0.01min remaining\n",
      " 54%      0.01min remaining\n",
      " 57%      0.01min remaining\n",
      " 63%      0.01min remaining\n",
      " 60%      0.01min remaining\n",
      " 66%      0.01min remaining\n",
      " 72%      0.01min remaining\n",
      " 69%      0.01min remaining\n",
      " 75%      0.01min remaining\n",
      " 81%      0.01min remaining\n",
      " 78%      0.01min remaining\n",
      " 84%      0.01min remaining\n",
      " 87%      0.01min remaining\n",
      " 90%      0.01min remaining\n",
      " 51%      0.01min remaining\n",
      " 96%      0.01min remaining\n",
      " 93%      0.01min remaining\n",
      "100%      0.00min remaining\n",
      "\n",
      "Total Time needed: 0.01min\n"
     ]
    }
   ],
   "source": [
    "models = p.start(Model, n, gtab_seen*n_variations, sphere=[sphere], isotropic=[BiExponentialIsotropicModel], solver=solvers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelization starts on 64 CPUs.\n",
      "  3%      0.01min remaining\n",
      "  6%      0.01min remaining\n",
      " 12%      0.01min remaining\n",
      "  9%      0.01min remaining\n",
      " 15%      0.01min remaining\n",
      " 18%      0.01min remaining\n",
      " 21%      0.01min remaining\n",
      " 24%      0.01min remaining\n",
      " 27%      0.02min remaining\n",
      " 30%      0.02min remaining\n",
      " 33%      0.02min remaining\n",
      " 36%      0.02min remaining\n",
      " 42%      0.02min remaining\n",
      " 39%      0.02min remaining\n",
      " 45%      0.03min remaining\n",
      " 48%      0.03min remaining\n",
      " 51%      0.03min remaining\n",
      " 54%      0.03min remaining\n",
      " 57%      0.03min remaining\n",
      " 60%      0.03min remaining\n",
      " 63%      0.03min remaining\n",
      " 66%      0.04min remaining\n",
      " 69%      0.04min remaining\n",
      " 72%      0.04min remaining\n",
      " 78%      0.04min remaining\n",
      " 75%      0.04min remaining\n",
      " 81%      0.05min remaining\n",
      " 87%      0.05min remaining\n",
      " 84%      0.05min remaining\n",
      " 90%      0.05min remaining\n",
      " 93%      0.06min remaining\n",
      " 96%      0.06min remaining\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-30114c333694>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_seen\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_variations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_seen\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_variations\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mg_seen\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_variations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/localhome/cpoetter/ISBI2015/parallelization.pyc\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, function, n, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[0mvox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mreturn_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvox\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/queues.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fits = p.start([i.fit for i in models], n, data_seen*n_variations, te_seen*n_variations,  g_seen*n_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicts = p.start([i.predict for i in fits], n, gtab_unseen*n_variations, te_unseen*n_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicts_seen = p.start([i.predict for i in fits], n, gtab_seen*n_variations, te_seen*n_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = 'predictions_seen.csv'\n",
    "#with open(filename, 'w') as f:\n",
    "#   writer = csv.writer(f, delimiter=',')\n",
    "#   writer.writerows(predicts_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e9d306af261c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m    \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m    \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predicts' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'predictions'\n",
    "with open(filename + '_' + version + '.csv', 'w') as f:\n",
    "   writer = csv.writer(f, delimiter=',')\n",
    "   writer.writerows(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas = []\n",
    "te_params = []\n",
    "iso_params = []\n",
    "S0s = []\n",
    "for i in fits:\n",
    "    betas.append(i.beta)\n",
    "    te_params.append(i.te_params)\n",
    "    iso_params.append(i.iso.params)\n",
    "    S0s.append([i.S0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'betas'\n",
    "with open(filename + '_' + version + '.csv', 'w') as f:\n",
    "   writer = csv.writer(f, delimiter=',')\n",
    "   writer.writerows(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'te_params'\n",
    "with open(filename + '_' + version + '.csv', 'w') as f:\n",
    "   writer = csv.writer(f, delimiter=',')\n",
    "   writer.writerows(te_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'iso_params'\n",
    "with open(filename + '_' + version + '.csv', 'w') as f:\n",
    "   writer = csv.writer(f, delimiter=',')\n",
    "   writer.writerows(iso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'S0s'\n",
    "with open(filename + '_' + version + '.csv', 'w') as f:\n",
    "   writer = csv.writer(f, delimiter=',')\n",
    "   writer.writerows(S0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSEs = np.zeros(n)\n",
    "for j in range(0,n):\n",
    "    LSEs[j] = utils.LSE(predicts[j], (data_unseen*n_variations)[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LSE_average = np.zeros(n_variations)\n",
    "for m in range(n_variations):\n",
    "    LSE_average[m] = np.mean(LSEs[range(m*n_voxels, (m+1)*n_voxels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Median LSE = %s\"%np.mean(LSEs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
